{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7e21aa",
   "metadata": {},
   "source": [
    "# Getting the dependency parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af2ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I need a ticket to Los Angeles on May 8th.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9eed15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\tPRON\tnsubj\tnominal subject\tneed\n",
      "need\tVERB\tROOT\tNone\tneed\n",
      "a\tDET\tdet\tdeterminer\tticket\n",
      "ticket\tNOUN\tdobj\tdirect object\tneed\n",
      "to\tADP\tprep\tprepositional modifier\tticket\n",
      "Los\tPROPN\tcompound\tcompound\tAngeles\n",
      "Angeles\tPROPN\tpobj\tobject of preposition\tto\n",
      "on\tADP\tprep\tprepositional modifier\tneed\n",
      "May\tPROPN\tcompound\tcompound\t8th\n",
      "8th\tNOUN\tpobj\tobject of preposition\ton\n",
      ".\tPUNCT\tpunct\tpunctuation\tneed\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sent)\n",
    "\n",
    "for token in doc:\n",
    "    print('%s\\t%s\\t%s\\t%s\\t%s' %(token.text, token.pos_, token.dep_, \\\n",
    "                        spacy.explain(token.dep_), token.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679148e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los GPE\n",
      "Angeles GPE\n",
      "May DATE\n",
      "8th DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sent)\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.text, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3af69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "nearly MONEY\n",
      "$ MONEY\n",
      "100 MONEY\n",
      "million MONEY\n",
      "Tim PERSON\n",
      "Cook PERSON\n"
     ]
    }
   ],
   "source": [
    "ner_s = 'Apple investors urged to vote against a nearly \\\n",
    "$100 million pay package for CEO Tim Cook.'\n",
    "\n",
    "doc = nlp(ner_s)\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.text, token.ent_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500c919",
   "metadata": {},
   "source": [
    "# Extracting noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da927121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple investors\n",
      "a nearly $100 million pay package\n",
      "CEO\n",
      "Tim Cook\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433152a",
   "metadata": {},
   "source": [
    "# Extracting subjects, predicates, and objects of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f708613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\tPRON\tnsubj\tnominal subject\testablished\t1\n",
      "established\tVERB\tROOT\tNone\testablished\t1\n",
      "my\tPRON\tposs\tpossession modifier\tworkshop\t4\n",
      "own\tADJ\tamod\tadjectival modifier\tworkshop\t4\n",
      "workshop\tNOUN\tdobj\tdirect object\testablished\t1\n",
      "in\tADP\tprep\tprepositional modifier\testablished\t1\n",
      "2018\tNUM\tpobj\tobject of preposition\tin\t5\n",
      "before\tSCONJ\tmark\tmarker\twent\t9\n",
      "I\tPRON\tnsubj\tnominal subject\twent\t9\n",
      "went\tVERB\tadvcl\tadverbial clause modifier\testablished\t1\n",
      "to\tADP\tprep\tprepositional modifier\twent\t9\n",
      "Japan\tPROPN\tpobj\tobject of preposition\tto\t10\n",
      ".\tPUNCT\tpunct\tpunctuation\testablished\t1\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I established my own workshop in 2018 before I went to Japan.'\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    print('%s\\t%s\\t%s\\t%s\\t%s\\t%d' %(token.text, token.pos_, token.dep_, \\\n",
    "                        spacy.explain(token.dep_), token.head.text, token.head.i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d30c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I [I]\n",
      "established [I, established, my, own, workshop, in, 2018, before, I, went, to, Japan, .]\n",
      "my [my]\n",
      "own [own]\n",
      "workshop [my, own, workshop]\n",
      "in [in, 2018]\n",
      "2018 [2018]\n",
      "before [before]\n",
      "I [I]\n",
      "went [before, I, went, to, Japan]\n",
      "to [to, Japan]\n",
      "Japan [Japan]\n",
      ". [.]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    subtree = list(token.subtree)\n",
    "    print(token, subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998f740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, established), (9, went)]\n"
     ]
    }
   ],
   "source": [
    "verb_idxs = [(i, token) for i, token in enumerate(doc) if token.pos_ == 'VERB']\n",
    "print(verb_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052c0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase(doc, head_idx, tag):\n",
    "    for token in doc:\n",
    "        if tag in token.dep_ and token.head.i == head_idx:\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            return doc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c185a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: I\n",
      "predicate: established\n",
      "object: my own workshop\n",
      "subject: I\n",
      "predicate: went\n",
      "object: None\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sentence)\n",
    "\n",
    "for verb_idx in verb_idxs:\n",
    "    subject_phrase = get_phrase(doc, verb_idx[0], 'subj')\n",
    "    object_phrase = get_phrase(doc, verb_idx[0], 'obj')\n",
    "    print('subject:', subject_phrase)\n",
    "    print('predicate:', doc[verb_idx[0]])\n",
    "    print('object:', object_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
